"""
APLICACI√ìN DE DETECCI√ìN DE FRAUDE EN TARJETAS DE CR√âDITO
Prueba T√©cnica - Cient√≠fico de Datos - Tenpo
Octubre 2025 - Versi√≥n Optimizada con Cach√©
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from pathlib import Path
import pickle
import os

# Configuraci√≥n de p√°gina
st.set_page_config(
    page_title="Detecci√≥n de Fraude - Tenpo",
    page_icon="üí≥",
    layout="wide",
    initial_sidebar_state="expanded"
)

warnings.filterwarnings('ignore')

# Importar m√≥dulos personalizados
from modules.data_loader import DataLoader
from modules.eda import ExploratoryDataAnalysis
from modules.feature_engineering import FeatureEngineer
from modules.feature_selection import FeatureSelector
from modules.model_trainer import ModelTrainer
from modules.model_evaluator import ModelEvaluator
from modules.predictor import Predictor
from modules.visualizations import Visualizer

# Directorio para cache
CACHE_DIR = Path("cache")
CACHE_DIR.mkdir(exist_ok=True)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeeba;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .cache-status {
        background-color: #e8f4f8;
        border-left: 4px solid #3498db;
        padding: 0.5rem;
        margin: 0.5rem 0;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# FUNCIONES DE CACH√â Y PERSISTENCIA
# ============================================================================

def save_to_cache(data, filename):
    """Guarda datos en cach√©"""
    try:
        filepath = CACHE_DIR / filename
        with open(filepath, 'wb') as f:
            pickle.dump(data, f)
        return True
    except Exception as e:
        st.error(f"Error al guardar cach√©: {str(e)}")
        return False

def load_from_cache(filename):
    """Carga datos desde cach√©"""
    try:
        filepath = CACHE_DIR / filename
        if filepath.exists():
            with open(filepath, 'rb') as f:
                return pickle.load(f)
        return None
    except Exception as e:
        st.error(f"Error al cargar cach√©: {str(e)}")
        return None

def check_cache_exists(filename):
    """Verifica si existe un archivo en cach√©"""
    return (CACHE_DIR / filename).exists()

def get_cache_info():
    """Obtiene informaci√≥n sobre archivos en cach√©"""
    cache_files = {
        'df_train.pkl': 'Datos de Entrenamiento',
        'df_test.pkl': 'Datos de Test',
        'df_fe.pkl': 'Feature Engineering',
        'feature_selection.pkl': 'Selecci√≥n de Features',
        'training_results.pkl': 'Modelos Entrenados',
        'predictions.pkl': 'Predicciones'
    }
    
    info = {}
    for filename, description in cache_files.items():
        filepath = CACHE_DIR / filename
        if filepath.exists():
            size_mb = filepath.stat().st_size / (1024 * 1024)
            info[description] = {
                'exists': True,
                'size': f"{size_mb:.2f} MB",
                'filename': filename
            }
        else:
            info[description] = {'exists': False}
    
    return info

def clear_cache():
    """Limpia todos los archivos de cach√©"""
    try:
        for file in CACHE_DIR.glob("*.pkl"):
            file.unlink()
        return True
    except Exception as e:
        st.error(f"Error al limpiar cach√©: {str(e)}")
        return False

# ============================================================================
# INICIALIZACI√ìN AUTOM√ÅTICA
# ============================================================================

def auto_initialize():
    """Inicializa autom√°ticamente los datos desde cach√© o archivos"""
    
    # Cargar datos de entrenamiento
    if 'df_train' not in st.session_state:
        df_train = load_from_cache('df_train.pkl')
        if df_train is not None:
            st.session_state.df_train = df_train
            st.session_state.data_loaded = True
        else:
            # Intentar cargar desde archivo CSV
            if Path("creditcard_train.csv").exists():
                try:
                    loader = DataLoader()
                    st.session_state.df_train = loader.load_data("creditcard_train.csv")
                    st.session_state.data_loaded = True
                    save_to_cache(st.session_state.df_train, 'df_train.pkl')
                except:
                    st.session_state.data_loaded = False
    
    # Cargar datos de test
    if 'df_test' not in st.session_state:
        df_test = load_from_cache('df_test.pkl')
        if df_test is not None:
            st.session_state.df_test = df_test
        else:
            if Path("creditcard_test.csv").exists():
                try:
                    loader = DataLoader()
                    st.session_state.df_test = loader.load_data("creditcard_test.csv")
                    save_to_cache(st.session_state.df_test, 'df_test.pkl')
                except:
                    pass
    
    # Cargar feature engineering
    if 'df_fe' not in st.session_state:
        df_fe = load_from_cache('df_fe.pkl')
        if df_fe is not None:
            st.session_state.df_fe = df_fe
    
    # Cargar feature selection
    if 'feature_selection_results' not in st.session_state:
        feature_selection = load_from_cache('feature_selection.pkl')
        if feature_selection is not None:
            st.session_state.feature_selection_results = feature_selection['results']
            st.session_state.selected_features = feature_selection['selected_features']
    
    # Cargar modelos entrenados
    if 'training_results' not in st.session_state:
        training_results = load_from_cache('training_results.pkl')
        if training_results is not None:
            st.session_state.training_results = training_results
            st.session_state.model_trained = True
            
            # Cargar trainer
            trainer = load_from_cache('trainer.pkl')
            if trainer is not None:
                st.session_state.trainer = trainer
    
    # Cargar predicciones
    if 'predictions' not in st.session_state:
        predictions = load_from_cache('predictions.pkl')
        if predictions is not None:
            st.session_state.predictions = predictions
            st.session_state.predictions_made = True
    
    # Estados por defecto
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False
    if 'model_trained' not in st.session_state:
        st.session_state.model_trained = False
    if 'predictions_made' not in st.session_state:
        st.session_state.predictions_made = False

# ============================================================================
# FUNCI√ìN PRINCIPAL
# ============================================================================

def main():
    """Funci√≥n principal de la aplicaci√≥n"""
    
    # Inicializaci√≥n autom√°tica
    auto_initialize()
    
    # Header
    st.markdown('<div class="main-header">üí≥ Sistema de Detecci√≥n de Fraude</div>', 
                unsafe_allow_html=True)
    st.markdown("### Prueba T√©cnica - Cient√≠fico de Datos - Tenpo")
    st.markdown("---")
    
    # Sidebar
    with st.sidebar:
        st.image("https://via.placeholder.com/250x80/1f77b4/ffffff?text=TENPO", 
                 use_container_width=True)
        st.markdown("## üìã Navegaci√≥n")
        
        page = st.radio(
            "Seleccione una secci√≥n:",
            [
                "üè† Inicio",
                "üìä An√°lisis Exploratorio",
                "üîß Ingenier√≠a de Features",
                "üéØ Selecci√≥n de Features",
                "ü§ñ Entrenamiento de Modelos",
                "üìà Evaluaci√≥n de Modelos",
                "üîÆ Predicciones",
                "üìÑ Reporte Final"
            ]
        )
        
        st.markdown("---")
        st.markdown("### ‚öôÔ∏è Gesti√≥n de Cach√©")
        
        # Mostrar estado del cach√©
        cache_info = get_cache_info()
        
        with st.expander("üì¶ Estado del Cach√©", expanded=False):
            for description, info in cache_info.items():
                if info['exists']:
                    st.markdown(f"‚úÖ **{description}**: {info['size']}")
                else:
                    st.markdown(f"‚ùå **{description}**: No disponible")
        
        # Botones de gesti√≥n
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üîÑ Recargar Datos", use_container_width=True):
                with st.spinner("Recargando datos..."):
                    try:
                        loader = DataLoader()
                        st.session_state.df_train = loader.load_data("creditcard_train.csv")
                        st.session_state.df_test = loader.load_data("creditcard_test.csv")
                        st.session_state.data_loaded = True
                        
                        save_to_cache(st.session_state.df_train, 'df_train.pkl')
                        save_to_cache(st.session_state.df_test, 'df_test.pkl')
                        
                        st.success("‚úÖ Datos recargados!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"‚ùå Error: {str(e)}")
        
        with col2:
            if st.button("üóëÔ∏è Limpiar Cach√©", use_container_width=True):
                if clear_cache():
                    # Limpiar session state
                    for key in list(st.session_state.keys()):
                        del st.session_state[key]
                    st.success("‚úÖ Cach√© limpiado!")
                    st.rerun()
        
        # Informaci√≥n del sistema
        st.markdown("---")
        st.markdown("### üìä Estado del Sistema")
        
        status_items = [
            ("Datos", st.session_state.data_loaded),
            ("Feature Eng.", 'df_fe' in st.session_state),
            ("Feat. Selection", 'selected_features' in st.session_state),
            ("Modelo", st.session_state.model_trained),
            ("Predicciones", st.session_state.predictions_made)
        ]
        
        for item, status in status_items:
            icon = "‚úÖ" if status else "‚è≥"
            st.markdown(f"{icon} {item}")
    
    # Contenido principal seg√∫n la p√°gina seleccionada
    if page == "üè† Inicio":
        show_home_page()
    elif page == "üìä An√°lisis Exploratorio":
        show_eda_page()
    elif page == "üîß Ingenier√≠a de Features":
        show_feature_engineering_page()
    elif page == "üéØ Selecci√≥n de Features":
        show_feature_selection_page()
    elif page == "ü§ñ Entrenamiento de Modelos":
        show_model_training_page()
    elif page == "üìà Evaluaci√≥n de Modelos":
        show_model_evaluation_page()
    elif page == "üîÆ Predicciones":
        show_predictions_page()
    elif page == "üìÑ Reporte Final":
        show_report_page()

# ============================================================================
# P√ÅGINAS (mantener las mismas pero con modificaciones para cach√©)
# ============================================================================

def show_home_page():
    """P√°gina de inicio"""
    st.markdown("## üè† Bienvenido al Sistema de Detecci√≥n de Fraude")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### üìù Descripci√≥n del Proyecto
        
        Este sistema permite desarrollar y evaluar modelos de Machine Learning para 
        detectar transacciones fraudulentas en tarjetas de cr√©dito, minimizando los 
        falsos positivos que generan cancelaciones del servicio.
        
        ### üéØ Objetivos
        
        1. **An√°lisis Exploratorio**: Comprender el comportamiento de los datos
        2. **Ingenier√≠a de Features**: Crear caracter√≠sticas relevantes
        3. **Selecci√≥n de Features**: Identificar las variables m√°s importantes
        4. **Modelado**: Entrenar y comparar diferentes algoritmos
        5. **Evaluaci√≥n**: Analizar m√©tricas y desempe√±o
        6. **Predicci√≥n**: Generar resultados en conjunto de test
        
        ### üìä Metodolog√≠a
        
        - **Feature Engineering**: Transformaciones, interacciones y agregaciones
        - **Selecci√≥n de Features**: F-Score, Informaci√≥n Mutua, Random Forest, PCA
        - **T√©cnicas de Balanceo**: Undersampling, SMOTE, ADASYN, Class Weights
        - **Modelos**: Random Forest, XGBoost, Redes Neuronales
        - **Evaluaci√≥n**: F1-Score, ROC-AUC, Precision-Recall
        
        ### ‚ö° Caracter√≠sticas de Optimizaci√≥n
        
        - **Cach√© Autom√°tico**: Los datos y modelos se guardan autom√°ticamente
        - **Carga R√°pida**: No necesita reprocesar en cada sesi√≥n
        - **Persistencia**: Los resultados se mantienen entre sesiones
        """)
    
    with col2:
        st.markdown("### üìà Estado del Proyecto")
        
        if st.session_state.data_loaded:
            st.success("‚úÖ Datos cargados")
            if 'df_train' in st.session_state:
                st.info(f"üìä Train: {len(st.session_state.df_train):,} registros")
            if 'df_test' in st.session_state:
                st.info(f"üìä Test: {len(st.session_state.df_test):,} registros")
        else:
            st.warning("‚ö†Ô∏è Datos no cargados")
            st.info("üîÑ Coloque los archivos CSV en el directorio")
        
        if 'df_fe' in st.session_state:
            st.success("‚úÖ Feature Engineering aplicado")
        else:
            st.warning("‚è≥ Feature Engineering pendiente")
        
        if 'selected_features' in st.session_state:
            st.success("‚úÖ Features seleccionadas")
            st.info(f"üéØ {len(st.session_state.selected_features)} features")
        else:
            st.warning("‚è≥ Selecci√≥n pendiente")
        
        if st.session_state.model_trained:
            st.success("‚úÖ Modelo entrenado")
        else:
            st.warning("‚è≥ Modelo no entrenado")
        
        if st.session_state.predictions_made:
            st.success("‚úÖ Predicciones realizadas")
        else:
            st.warning("‚è≥ Predicciones pendientes")
    
    st.markdown("---")
    
    # Informaci√≥n de cach√©
    cache_info = get_cache_info()
    available_cache = sum(1 for info in cache_info.values() if info['exists'])
    
    if available_cache > 0:
        st.info(f"üíæ **{available_cache}** archivos disponibles en cach√© - El sistema cargar√° autom√°ticamente los datos guardados")

def show_feature_engineering_page():
    """P√°gina de ingenier√≠a de caracter√≠sticas"""
    st.markdown("## üîß Ingenier√≠a de Caracter√≠sticas")
    
    if not st.session_state.data_loaded:
        st.warning("‚ö†Ô∏è Por favor, aseg√∫rese de que los datos est√©n cargados")
        return
    
    df_train = st.session_state.df_train
    engineer = FeatureEngineer()
    
    # Verificar si ya existe feature engineering
    if 'df_fe' in st.session_state:
        st.success("‚úÖ Feature Engineering ya aplicado (cargado desde cach√©)")
        
        col1, col2, col3 = st.columns(3)
        col1.metric("Features Originales", df_train.shape[1] - 1)
        col2.metric("Features Creadas", st.session_state.df_fe.shape[1] - df_train.shape[1])
        col3.metric("Total Features", st.session_state.df_fe.shape[1] - 1)
        
        st.markdown("#### Muestra de nuevas features")
        new_cols = [col for col in st.session_state.df_fe.columns if col not in df_train.columns]
        st.dataframe(st.session_state.df_fe[new_cols[:15]].head(10), use_container_width=True)
        
        if st.button("üîÑ Regenerar Feature Engineering", use_container_width=True):
            with st.spinner("Regenerando features..."):
                df_fe = engineer.create_features(df_train)
                st.session_state.df_fe = df_fe
                save_to_cache(df_fe, 'df_fe.pkl')
                st.success("‚úÖ Feature Engineering regenerado!")
                st.rerun()
        
        return
    
    st.markdown("""
    ### üìù Transformaciones Aplicadas
    
    Se aplicar√°n las siguientes transformaciones para crear nuevas caracter√≠sticas:
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **1. Transformaciones de Amount:**
        - Logaritmo: `log(Amount + 1)`
        - Ra√≠z cuadrada: `sqrt(Amount)`
        - Cuadrado: `Amount¬≤`
        - Cubo: `Amount¬≥`
        
        **2. Transformaciones de Time:**
        - Hora del d√≠a: `(Time / 3600) % 24`
        - D√≠a: `Time / 86400`
        - Transformaci√≥n c√≠clica (sin, cos)
        """)
    
    with col2:
        st.markdown("""
        **3. Interacciones:**
        - Productos entre V-features importantes
        - Ratios entre V-features
        
        **4. Agregaciones estad√≠sticas:**
        - Media, desviaci√≥n, min, max
        - Mediana, asimetr√≠a, curtosis
        """)
    
    if st.button("üöÄ Aplicar Feature Engineering", use_container_width=True):
        with st.spinner("Aplicando transformaciones..."):
            df_fe = engineer.create_features(df_train)
            st.session_state.df_fe = df_fe
            
            # Guardar en cach√©
            save_to_cache(df_fe, 'df_fe.pkl')
            
            col1, col2, col3 = st.columns(3)
            col1.metric("Features Originales", df_train.shape[1] - 1)
            col2.metric("Features Creadas", df_fe.shape[1] - df_train.shape[1])
            col3.metric("Total Features", df_fe.shape[1] - 1)
            
            st.success("‚úÖ Feature Engineering completado y guardado en cach√©!")
            
            st.markdown("#### Muestra de nuevas features")
            new_cols = [col for col in df_fe.columns if col not in df_train.columns]
            st.dataframe(df_fe[new_cols[:15]].head(10), use_container_width=True)

def show_feature_selection_page():
    """P√°gina de selecci√≥n de caracter√≠sticas"""
    st.markdown("## üéØ Selecci√≥n de Caracter√≠sticas")
    
    if not st.session_state.data_loaded:
        st.warning("‚ö†Ô∏è Por favor, cargue los datos primero")
        return
    
    if 'df_fe' not in st.session_state:
        st.warning("‚ö†Ô∏è Por favor, aplique Feature Engineering primero")
        return
    
    df_fe = st.session_state.df_fe
    selector = FeatureSelector()
    viz = Visualizer()
    
    # Verificar si ya existe selecci√≥n
    if 'feature_selection_results' in st.session_state:
        st.success("‚úÖ Selecci√≥n de Features ya realizada (cargado desde cach√©)")
        
        results = st.session_state.feature_selection_results
        methods = list(results.keys())
        
        # Mostrar resultados por m√©todo
        tabs = st.tabs([f"üìä {method}" for method in methods])
        
        for i, method in enumerate(methods):
            with tabs[i]:
                if method in results:
                    st.markdown(f"### Top 20 Features - {method}")
                    st.dataframe(
                        results[method]['scores'].head(20),
                        use_container_width=True
                    )
                    
                    if method != "PCA":
                        st.markdown("#### Importancia de Features")
                        fig = viz.plot_feature_importance(
                            results[method]['scores'].head(20)
                        )
                        st.pyplot(fig)
        
        # Features seleccionadas finales
        st.markdown("---")
        st.markdown("### ‚úÖ Features Seleccionadas")
        
        col1, col2 = st.columns(2)
        col1.metric("Total Features Seleccionadas", len(st.session_state.selected_features))
        X = df_fe.drop('Class', axis=1)
        col2.metric("Reducci√≥n", 
                   f"{(1 - len(st.session_state.selected_features)/X.shape[1])*100:.1f}%")
        
        if st.button("üîÑ Regenerar Selecci√≥n", use_container_width=True):
            # Limpiar para permitir regeneraci√≥n
            del st.session_state.feature_selection_results
            del st.session_state.selected_features
            st.rerun()
        
        return
    
    st.markdown("""
    ### üìä Metodolog√≠as de Selecci√≥n
    
    Se aplicar√°n diferentes m√©todos para identificar las caracter√≠sticas m√°s relevantes:
    """)
    
    methods = st.multiselect(
        "Seleccione los m√©todos a aplicar:",
        ["F-Score", "Informaci√≥n Mutua", "Random Forest", "PCA"],
        default=["F-Score", "Informaci√≥n Mutua", "Random Forest"]
    )
    
    n_features = st.slider("N√∫mero de features a seleccionar por m√©todo:", 20, 100, 40)
    
    if st.button("üéØ Ejecutar Selecci√≥n de Features", use_container_width=True):
        with st.spinner("Seleccionando caracter√≠sticas..."):
            X = df_fe.drop('Class', axis=1)
            y = df_fe['Class']
            
            results = selector.select_features(X, y, methods, n_features)
            st.session_state.feature_selection_results = results
            
            # Mostrar resultados por m√©todo
            tabs = st.tabs([f"üìä {method}" for method in methods])
            
            for i, method in enumerate(methods):
                with tabs[i]:
                    if method in results:
                        st.markdown(f"### Top 20 Features - {method}")
                        st.dataframe(
                            results[method]['scores'].head(20),
                            use_container_width=True
                        )
                        
                        if method != "PCA":
                            st.markdown("#### Importancia de Features")
                            fig = viz.plot_feature_importance(
                                results[method]['scores'].head(20)
                            )
                            st.pyplot(fig)
            
            # Features seleccionadas finales
            st.markdown("---")
            st.markdown("### ‚úÖ Features Seleccionadas (Uni√≥n de todos los m√©todos)")
            
            all_features = set()
            for method in methods:
                if method in results and method != "PCA":
                    all_features.update(results[method]['selected_features'])
            
            st.session_state.selected_features = list(all_features)
            
            # Guardar en cach√©
            cache_data = {
                'results': results,
                'selected_features': list(all_features)
            }
            save_to_cache(cache_data, 'feature_selection.pkl')
            
            col1, col2 = st.columns(2)
            col1.metric("Total Features Seleccionadas", len(all_features))
            col2.metric("Reducci√≥n", 
                       f"{(1 - len(all_features)/X.shape[1])*100:.1f}%")
            
            st.success("‚úÖ Selecci√≥n de caracter√≠sticas completada y guardada en cach√©!")

def show_model_training_page():
    """P√°gina de entrenamiento de modelos"""
    st.markdown("## ü§ñ Entrenamiento de Modelos")
    
    if not st.session_state.data_loaded:
        st.warning("‚ö†Ô∏è Por favor, cargue los datos primero")
        return
    
    if 'selected_features' not in st.session_state:
        st.warning("‚ö†Ô∏è Por favor, complete la selecci√≥n de features primero")
        return
    
    # Verificar si ya hay modelo entrenado
    if st.session_state.model_trained and 'training_results' in st.session_state:
        st.success("‚úÖ Modelos ya entrenados (cargado desde cach√©)")
        
        results = st.session_state.training_results
        results_df = pd.DataFrame(results['all_results'])
        
        display_cols = [col for col in results_df.columns 
                       if col not in ['model', 'y_pred', 'y_proba']]
        st.dataframe(results_df[display_cols], use_container_width=True)
        
        # Mejor modelo
        best_idx = results_df['F1-Score'].idxmax()
        best_model = results_df.loc[best_idx]
        
        st.markdown("### üèÜ Mejor Modelo")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Modelo", best_model['Modelo'])
        col2.metric("T√©cnica", best_model['T√©cnica'])
        col3.metric("F1-Score", f"{best_model['F1-Score']:.4f}")
        col4.metric("ROC-AUC", f"{best_model['ROC-AUC']:.4f}")
        
        if st.button("üîÑ Reentrenar Modelos", use_container_width=True):
            # Limpiar para permitir reentrenamiento
            del st.session_state.training_results
            del st.session_state.trainer
            st.session_state.model_trained = False
            st.rerun()
        
        return
    
    trainer = ModelTrainer()
    
    st.markdown("### ‚öôÔ∏è Configuraci√≥n de Entrenamiento")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### Modelos a entrenar")
        models_to_train = st.multiselect(
            "Seleccione los modelos:",
            ["Random Forest", "XGBoost", "Red Neuronal"],
            default=["Random Forest", "XGBoost"]
        )
    
    with col2:
        st.markdown("#### T√©cnicas de balanceo")
        balancing_techniques = st.multiselect(
            "Seleccione las t√©cnicas:",
            ["Sin Balanceo", "Undersampling", "SMOTE", "ADASYN", "Class Weights"],
            default=["SMOTE", "Class Weights"]
        )
    
    test_size = st.slider("Tama√±o del conjunto de test (%):", 10, 40, 30) / 100
    
    if st.button("üöÄ Entrenar Modelos", use_container_width=True):
        with st.spinner("Entrenando modelos... Esto puede tomar varios minutos"):
            df_fe = st.session_state.df_fe
            selected_features = st.session_state.selected_features
            
            X = df_fe[selected_features]
            y = df_fe['Class']
            
            results = trainer.train_models(
                X, y, 
                models_to_train, 
                balancing_techniques,
                test_size
            )
            
            st.session_state.training_results = results
            st.session_state.trainer = trainer
            st.session_state.model_trained = True
            
            # Guardar en cach√©
            save_to_cache(results, 'training_results.pkl')
            save_to_cache(trainer, 'trainer.pkl')
            
            st.success("‚úÖ Entrenamiento completado y guardado en cach√©!")
            
            # Mostrar resumen
            st.markdown("### üìä Resumen de Resultados")
            
            results_df = pd.DataFrame(results['all_results'])
            display_cols = [col for col in results_df.columns 
                           if col not in ['model', 'y_pred', 'y_proba']]
            st.dataframe(results_df[display_cols], use_container_width=True)
            
            # Mejor modelo
            best_idx = results_df['F1-Score'].idxmax()
            best_model = results_df.loc[best_idx]
            
            st.markdown("### üèÜ Mejor Modelo")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("Modelo", best_model['Modelo'])
            col2.metric("T√©cnica", best_model['T√©cnica'])
            col3.metric("F1-Score", f"{best_model['F1-Score']:.4f}")
            col4.metric("ROC-AUC", f"{best_model['ROC-AUC']:.4f}")

def show_eda_page():
    """P√°gina de an√°lisis exploratorio"""
    st.markdown("## üìä An√°lisis Exploratorio de Datos")
    
    if not st.session_state.data_loaded:
        st.warning("‚ö†Ô∏è Por favor, aseg√∫rese de que los datos est√©n cargados")
        return
    
    df_train = st.session_state.df_train
    eda = ExploratoryDataAnalysis(df_train)
    viz = Visualizer()
    
    # Tabs para organizar el contenido
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìã Info B√°sica", 
        "‚öñÔ∏è Balance de Clases", 
        "üìà Distribuciones",
        "üîó Correlaciones"
    ])
    
    with tab1:
        st.markdown("### üìã Informaci√≥n del Dataset")
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Total Registros", f"{len(df_train):,}")
        col2.metric("Features", f"{df_train.shape[1]-1}")
        col3.metric("Valores Nulos", f"{df_train.isnull().sum().sum()}")
        col4.metric("Duplicados", f"{df_train.duplicated().sum()}")
        
        st.markdown("#### Primeros registros")
        st.dataframe(df_train.head(10), use_container_width=True)
        
        st.markdown("#### Estad√≠sticas descriptivas")
        st.dataframe(df_train.describe(), use_container_width=True)
    
    with tab2:
        st.markdown("### ‚öñÔ∏è An√°lisis de Balance de Clases")
        
        class_info = eda.analyze_class_distribution()
        
        col1, col2, col3 = st.columns(3)
        col1.metric("Transacciones Normales", 
                   f"{class_info['normal_count']:,}",
                   f"{class_info['normal_pct']:.4f}%")
        col2.metric("Transacciones Fraudulentas", 
                   f"{class_info['fraud_count']:,}",
                   f"{class_info['fraud_pct']:.4f}%")
        col3.metric("Ratio de Desbalance", 
                   f"1:{class_info['imbalance_ratio']:.0f}",
                   delta="Altamente desbalanceado", delta_color="off")
        
        st.markdown("#### Visualizaci√≥n del desbalance")
        fig = viz.plot_class_distribution(df_train['Class'])
        st.pyplot(fig)
    
    with tab3:
        st.markdown("### üìà Distribuciones de Variables")
        
        # Amount y Time
        st.markdown("#### An√°lisis de Amount y Time")
        fig = viz.plot_amount_time_analysis(df_train)
        st.pyplot(fig)
        
        # Top V features
        st.markdown("#### Top Features por Correlaci√≥n")
        correlation = df_train.corr()['Class'].abs().sort_values(ascending=False)
        top_features = correlation.head(9).index.tolist()[1:]  # Excluir Class
        
        fig = viz.plot_feature_distributions(df_train, top_features)
        st.pyplot(fig)
    
    with tab4:
        st.markdown("### üîó An√°lisis de Correlaciones")
        
        correlation = df_train.corr()['Class'].abs().sort_values(ascending=False)
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown("#### Top 15 Correlaciones")
            st.dataframe(
                correlation.head(16).to_frame().rename(columns={'Class': 'Correlaci√≥n'}),
                use_container_width=True
            )
        
        with col2:
            st.markdown("#### Matriz de Correlaci√≥n")
            top_features = correlation.head(16).index.tolist()
            fig = viz.plot_correlation_matrix(df_train[top_features])
            st.pyplot(fig)

def show_model_evaluation_page():
    """P√°gina de evaluaci√≥n de modelos"""
    st.markdown("## üìà Evaluaci√≥n de Modelos")
    
    if not st.session_state.model_trained:
        st.warning("‚ö†Ô∏è Por favor, entrene los modelos primero")
        return
    
    results = st.session_state.training_results
    evaluator = ModelEvaluator()
    viz = Visualizer()
    
    # Comparaci√≥n de modelos
    st.markdown("### üìä Comparaci√≥n de Modelos")
    
    results_df = pd.DataFrame(results['all_results'])
    display_cols = [col for col in results_df.columns 
                   if col not in ['model', 'y_pred', 'y_proba']]
    
    # Gr√°fico de comparaci√≥n
    fig = viz.plot_model_comparison(results_df[display_cols])
    st.pyplot(fig)
    
    # Mejor modelo
    st.markdown("---")
    st.markdown("### üèÜ An√°lisis del Mejor Modelo")
    
    best_model_data = results['best_model']
    
    col1, col2, col3, col4, col5 = st.columns(5)
    col1.metric("F1-Score", f"{best_model_data['metrics']['F1-Score']:.4f}")
    col2.metric("ROC-AUC", f"{best_model_data['metrics']['ROC-AUC']:.4f}")
    col3.metric("Precision", f"{best_model_data['metrics']['Precision']:.4f}")
    col4.metric("Recall", f"{best_model_data['metrics']['Recall']:.4f}")
    col5.metric("Accuracy", f"{best_model_data['metrics']['Accuracy']:.4f}")
    
    # Matriz de confusi√≥n y curvas
    tab1, tab2, tab3 = st.tabs(["üî≤ Matriz de Confusi√≥n", "üìà Curva ROC", "üìä Precision-Recall"])
    
    with tab1:
        fig = viz.plot_confusion_matrix(
            best_model_data['y_test'],
            best_model_data['y_pred']
        )
        st.pyplot(fig)
    
    with tab2:
        fig = viz.plot_roc_curve(
            best_model_data['y_test'],
            best_model_data['y_proba']
        )
        st.pyplot(fig)
    
    with tab3:
        fig = viz.plot_precision_recall_curve(
            best_model_data['y_test'],
            best_model_data['y_proba']
        )
        st.pyplot(fig)

def show_predictions_page():
    """P√°gina de predicciones"""
    st.markdown("## üîÆ Generaci√≥n de Predicciones")
    
    if not st.session_state.model_trained:
        st.warning("‚ö†Ô∏è Por favor, entrene los modelos primero")
        return
    
    # Verificar si ya hay predicciones
    if st.session_state.predictions_made and 'predictions' in st.session_state:
        st.success("‚úÖ Predicciones ya generadas (cargado desde cach√©)")
        
        predictions = st.session_state.predictions
        
        # Estad√≠sticas
        col1, col2, col3 = st.columns(3)
        col1.metric("Total Predicciones", len(predictions['y_pred']))
        col2.metric("Normal", 
                   f"{(predictions['y_pred']==0).sum():,}",
                   f"{(predictions['y_pred']==0).sum()/len(predictions['y_pred'])*100:.2f}%")
        col3.metric("Fraude", 
                   f"{(predictions['y_pred']==1).sum():,}",
                   f"{(predictions['y_pred']==1).sum()/len(predictions['y_pred'])*100:.2f}%")
        
        # Distribuci√≥n de probabilidades
        st.markdown("### üìä Distribuci√≥n de Probabilidades")
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.hist(predictions['y_proba'], bins=50, edgecolor='black', alpha=0.7)
        ax.axvline(predictions['threshold'], color='red', linestyle='--', linewidth=2,
                  label=f'Threshold: {predictions["threshold"]}')
        ax.set_xlabel('Probabilidad de Fraude')
        ax.set_ylabel('Frecuencia')
        ax.set_title('Distribuci√≥n de Probabilidades Predichas')
        ax.legend()
        ax.grid(True, alpha=0.3)
        st.pyplot(fig)
        
        # Descargar archivo
        if Path('creditcard_test_evaluate.csv').exists():
            with open('creditcard_test_evaluate.csv', 'rb') as f:
                st.download_button(
                    label="üì• Descargar Predicciones (CSV)",
                    data=f,
                    file_name='creditcard_test_evaluate.csv',
                    mime='text/csv',
                    use_container_width=True
                )
        
        if st.button("üîÑ Regenerar Predicciones", use_container_width=True):
            del st.session_state.predictions
            st.session_state.predictions_made = False
            st.rerun()
        
        return
    
    predictor = Predictor()
    
    st.markdown("""
    ### üìù Generar Predicciones en Conjunto de Test
    
    Esta secci√≥n genera las predicciones finales en el archivo de test usando el mejor modelo entrenado.
    """)
    
    threshold = st.slider(
        "Threshold de clasificaci√≥n:",
        0.1, 0.9, 0.5, 0.01,
        help="Probabilidad m√≠nima para clasificar como fraude"
    )
    
    if st.button("üéØ Generar Predicciones", use_container_width=True):
        with st.spinner("Generando predicciones..."):
            df_test = st.session_state.df_test
            trainer = st.session_state.trainer
            selected_features = st.session_state.selected_features
            
            # Aplicar feature engineering al test
            engineer = FeatureEngineer()
            df_test_fe = engineer.create_features(df_test)
            
            # Hacer predicciones
            predictions = predictor.predict(
                trainer.best_model,
                df_test_fe,
                selected_features,
                trainer.scaler,
                threshold
            )
            
            st.session_state.predictions = predictions
            st.session_state.predictions_made = True
            
            # Guardar en cach√©
            save_to_cache(predictions, 'predictions.pkl')
            
            # Guardar archivo
            output_df = pd.DataFrame({'Class': predictions['y_pred']})
            output_df.to_csv('creditcard_test_evaluate.csv', index=False)
            
            st.success("‚úÖ Predicciones generadas y guardadas!")
            
            # Estad√≠sticas
            col1, col2, col3 = st.columns(3)
            col1.metric("Total Predicciones", len(predictions['y_pred']))
            col2.metric("Normal", 
                       f"{(predictions['y_pred']==0).sum():,}",
                       f"{(predictions['y_pred']==0).sum()/len(predictions['y_pred'])*100:.2f}%")
            col3.metric("Fraude", 
                       f"{(predictions['y_pred']==1).sum():,}",
                       f"{(predictions['y_pred']==1).sum()/len(predictions['y_pred'])*100:.2f}%")
            
            # Distribuci√≥n de probabilidades
            st.markdown("### üìä Distribuci√≥n de Probabilidades")
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.hist(predictions['y_proba'], bins=50, edgecolor='black', alpha=0.7)
            ax.axvline(threshold, color='red', linestyle='--', linewidth=2,
                      label=f'Threshold: {threshold}')
            ax.set_xlabel('Probabilidad de Fraude')
            ax.set_ylabel('Frecuencia')
            ax.set_title('Distribuci√≥n de Probabilidades Predichas')
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            
            # Descargar archivo
            with open('creditcard_test_evaluate.csv', 'rb') as f:
                st.download_button(
                    label="üì• Descargar Predicciones (CSV)",
                    data=f,
                    file_name='creditcard_test_evaluate.csv',
                    mime='text/csv',
                    use_container_width=True
                )

def show_report_page():
    """P√°gina de reporte final"""
    st.markdown("## üìÑ Reporte Final")
    
    if not st.session_state.model_trained:
        st.warning("‚ö†Ô∏è Complete el proceso de entrenamiento primero")
        return
    
    st.markdown("""
    ### üìä Resumen Ejecutivo
    
    #### üéØ Objetivo del Proyecto
    Desarrollar un modelo de Machine Learning para detectar transacciones fraudulentas 
    en tarjetas de cr√©dito, minimizando los falsos positivos que generan cancelaciones del servicio.
    """)
    
    # Informaci√≥n del dataset
    st.markdown("#### üìà Dataset")
    df_train = st.session_state.df_train
    class_counts = df_train['Class'].value_counts()
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Total Registros", f"{len(df_train):,}")
    col2.metric("Features Originales", df_train.shape[1] - 1)
    col3.metric("Ratio Desbalance", f"1:{int(class_counts[0]/class_counts[1])}")
    
    # Metodolog√≠a
    st.markdown("""
    #### üîß Metodolog√≠a Aplicada
    
    **1. An√°lisis Exploratorio**
    - An√°lisis de distribuciones
    - Identificaci√≥n de desbalance de clases
    - An√°lisis de correlaciones
    
    **2. Ingenier√≠a de Caracter√≠sticas**
    - Transformaciones de Amount (log, sqrt, cuadrado, cubo)
    - Transformaciones c√≠clicas de Time
    - Interacciones entre features
    - Agregaciones estad√≠sticas
    
    **3. Selecci√≥n de Caracter√≠sticas**
    - F-Score (An√°lisis Univariado)
    - Informaci√≥n Mutua
    - Random Forest Importance
    - PCA (opcional)
    
    **4. T√©cnicas de Balanceo**
    - Random Undersampling
    - SMOTE
    - ADASYN
    - Class Weights / scale_pos_weight
    
    **5. Modelos Entrenados**
    - Random Forest
    - XGBoost
    - Redes Neuronales Profundas
    """)
    
    # Resultados
    if 'training_results' in st.session_state:
        st.markdown("#### üèÜ Resultados del Mejor Modelo")
        
        best_model = st.session_state.training_results['best_model']
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Configuraci√≥n:**")
            st.write(f"- Modelo: {best_model['model_type']}")
            st.write(f"- T√©cnica: {best_model['technique']}")
            if 'selected_features' in st.session_state:
                st.write(f"- Features: {len(st.session_state.selected_features)}")
        
        with col2:
            st.markdown("**M√©tricas:**")
            st.write(f"- F1-Score: {best_model['metrics']['F1-Score']:.4f}")
            st.write(f"- ROC-AUC: {best_model['metrics']['ROC-AUC']:.4f}")
            st.write(f"- Precision: {best_model['metrics']['Precision']:.4f}")
            st.write(f"- Recall: {best_model['metrics']['Recall']:.4f}")
    
    # Justificaci√≥n de m√©tricas
    st.markdown("""
    #### üìä Justificaci√≥n de M√©tricas
    
    **M√©trica Principal Recomendada: F1-Score y ROC-AUC**
    
    **¬øPor qu√© NO usar Accuracy?**
    - Dataset altamente desbalanceado (< 1% fraudes)
    - Un modelo que prediga siempre "Normal" tendr√≠a alta accuracy pero ser√≠a in√∫til
    - Accuracy no es apropiada para clases desbalanceadas
    
    **¬øPor qu√© F1-Score?**
    - Balance √≥ptimo entre Precision y Recall
    - Penaliza tanto falsos positivos como falsos negativos
    - Apropiada para clases desbalanceadas
    - F√°cil de interpretar
    
    **¬øPor qu√© ROC-AUC?**
    - Independiente del threshold
    - Mide capacidad de discriminaci√≥n del modelo
    - Robusta ante desbalance de clases
    
    **Consideraciones de Negocio:**
    - **Falsos Positivos**: Bloqueos incorrectos ‚Üí Cancelaci√≥n del servicio
    - **Falsos Negativos**: Fraudes no detectados ‚Üí P√©rdidas econ√≥micas
    - Balance necesario entre ambos objetivos
    """)
    
    # Recomendaciones
    st.markdown("""
    #### üí° Recomendaciones
    
    **Para Implementaci√≥n:**
    1. Sistema de alertas graduales basado en probabilidad:
       - Prob > 0.9: Bloqueo autom√°tico
       - Prob 0.7-0.9: Revisi√≥n manual prioritaria
       - Prob 0.5-0.7: Monitoreo adicional
       - Prob < 0.5: Aprobar autom√°ticamente
    
    2. Monitoreo continuo de m√©tricas en producci√≥n
    
    3. Sistema de feedback para mejora continua
    
    **Para Mejora Continua:**
    1. Re-entrenar el modelo mensualmente con nuevos datos
    2. A/B testing con diferentes thresholds
    3. Incorporar feedback de clientes y analistas
    4. Analizar casos de falsos positivos/negativos
    """)
    
    # Archivos generados
    st.markdown("#### üìÅ Archivos Generados")
    st.write("‚úÖ creditcard_test_evaluate.csv - Predicciones en conjunto de test")
    st.write("‚úÖ cache/ - Modelos y datos persistentes para carga r√°pida")
    st.write("‚úÖ Visualizaciones y an√°lisis en la aplicaci√≥n")
    
    # Sistema de cach√©
    st.markdown("---")
    st.markdown("### üíæ Sistema de Cach√© y Persistencia")
    
    cache_info = get_cache_info()
    
    st.markdown("""
    **Ventajas del sistema implementado:**
    - ‚ö° Carga autom√°tica de datos al iniciar
    - üíæ Los modelos entrenados se guardan autom√°ticamente
    - üîÑ No necesita reprocesar datos en cada sesi√≥n
    - üì¶ Gesti√≥n inteligente de memoria
    """)
    
    with st.expander("üìä Estado detallado del cach√©"):
        for description, info in cache_info.items():
            if info['exists']:
                st.success(f"‚úÖ **{description}**: {info['size']}")
            else:
                st.info(f"‚è≥ **{description}**: No generado a√∫n")
    
    # Contacto
    st.markdown("---")
    st.markdown("""
    ### üìß Informaci√≥n del Proyecto
    **Desarrollado por:** Sistema de Detecci√≥n de Fraude - Tenpo
    **Fecha:** Octubre 2025
    
    ---
    **An√°lisis completado exitosamente** ‚úÖ
    """)

if __name__ == "__main__":
    main()
